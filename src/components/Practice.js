import { useEffect, useRef, useState, useCallback } from "react";
import { toast } from "react-hot-toast";
import { API_BASE, LS, SURVEY } from "../App";

const FALLBACK_QUESTIONS = [
    "Tell me about a recent weekend activity you really enjoyed and why it was meaningful.",
    "Describe your favorite place at home and how you usually spend time there.",
    "Talk about a hobby you picked up recently and how you got into it.",
];

const TTS_VOICE = "shimmer";

function Practice({ setUi, setLoading, setLoadingText, setSavedHistory }) {
    // UI state
    const [question, setQuestion] = useState("");
    const [timeLeft, setTimeLeft] = useState(60);
    const [timerRunning, setTimerRunning] = useState(false);
    const [isFinished, setIsFinished] = useState(false);
    const [memo, setMemo] = useState("");
    const [needVideoGesture, setNeedVideoGesture] = useState(false);

    // Recording state
    const [mediaRecorder, setMediaRecorder] = useState(null);
    const [recMime, setRecMime] = useState("audio/webm");
    const [isRecording, setIsRecording] = useState(false);
    const [audioURL, setAudioURL] = useState("");

    // Refs
    const videoRef = useRef(null);
    const audioRef = useRef(null);
    const pendingAudioUrlRef = useRef(null);

    // Question bank
    const [questionBank, setQuestionBank] = useState([]);
    const [bankLoading, setBankLoading] = useState(false);

    const playAudioAndVideo = useCallback(async (audioUrl) => {
        const audio = audioRef.current;
        const video = videoRef.current;
        if (!audio || !video) return;

        audio.src = audioUrl;
        audio.load();

        audio.onended = () => {
            video.pause();
            setTimeLeft(60);
            setTimerRunning(true);
        };

        video.currentTime = 0;

        try {
            await Promise.all([video.play(), audio.play()]);
            setNeedVideoGesture(false);
        } catch (error) {
            console.error("Autoplay was prevented:", error);
            pendingAudioUrlRef.current = audioUrl;
            setNeedVideoGesture(true);
            video.play().catch(e => console.error("Muted video also failed to play:", e));
        }
    }, []);

    const fetchQuestionBatch = useCallback(async () => {
        const level = localStorage.getItem(LS.level) || "IHâ€“AL";
        const role = localStorage.getItem(LS.role) || "";
        const residence = localStorage.getItem(LS.residence) || "";
        const recentCourse = localStorage.getItem(LS.recentCourse) || "";
        const selectedTopics = JSON.parse(localStorage.getItem(LS.topics) || "[]");

        const topicLabels = SURVEY.topics
            .filter(t => selectedTopics.includes(t.key))
            .map(t => t.label);

        const prompt = `
You are an expert OPIC coach. Generate 20 personalized, OPIC-style interview questions in English based on the user's profile.
- Return ONLY a valid JSON array of strings. No extra text or commentary.
- Each question: 14-22 words, single sentence, natural spoken style.
- Base questions on these topics: ${topicLabels.length > 0 ? topicLabels.join(', ') : 'General everyday topics'}.
- Reference Profile: Level: ${level}, Role: ${role}, Residence: ${residence}, Course: ${recentCourse}.
`.trim();

        try {
            setBankLoading(true);
            const res = await fetch(`${API_BASE}/ask`, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ question: prompt }),
            });
            if (!res.ok) throw new Error(`ask failed: ${res.status}`);
            const data = await res.json();
            const raw = data?.answer || "";
            const match = raw.match(/\[.*\]/s);
            let arr = [];
            if (match) {
                try { arr = JSON.parse(match[0]); } catch { arr = []; }
            }
            if (!Array.isArray(arr) || !arr.length) arr = FALLBACK_QUESTIONS;
            setQuestionBank(prev => [...prev, ...arr.filter(Boolean)]);
        } finally {
            setBankLoading(false);
        }
    }, []);

    const runOne = useCallback(async () => {
        setLoadingText("AIê°€ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤...");
        setLoading(true);
        setTimeLeft(60);
        setTimerRunning(false);
        setIsFinished(false);
        setMemo("");
        setAudioURL("");
        setNeedVideoGesture(false);

        try {
            let nextQuestion;
            if (questionBank.length > 0) {
                nextQuestion = questionBank[0];
                setQuestion(nextQuestion);
                setQuestionBank(prev => prev.slice(1));
            } else {
                await fetchQuestionBatch();
                const fetchedBank = await new Promise(resolve => {
                    setQuestionBank(currentBank => {
                        resolve(currentBank);
                        return currentBank;
                    });
                });
                nextQuestion = fetchedBank[0] || FALLBACK_QUESTIONS[Math.floor(Math.random() * FALLBACK_QUESTIONS.length)];
                setQuestion(nextQuestion);
                setQuestionBank(prev => prev.slice(1));
            }

            const res = await fetch(`${API_BASE}/tts`, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ text: nextQuestion, voice: TTS_VOICE }),
            });

            if (!res.ok) throw new Error("TTS request failed");
            const audioBlob = await res.blob();
            const audioUrl = URL.createObjectURL(audioBlob);
            await playAudioAndVideo(audioUrl);

        } catch (e) {
            console.error("runOne failed", e);
            toast.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        } finally {
            setLoading(false);
            if (questionBank.length < 5 && !bankLoading) {
                fetchQuestionBatch();
            }
        }
    }, [bankLoading, fetchQuestionBatch, playAudioAndVideo, questionBank, setLoading, setLoadingText]);


    useEffect(() => {
        runOne();
        // eslint-disable-next-line react-hooks/exhaustive-deps
    }, []);

    useEffect(() => {
        if (!timerRunning) return;
        if (timeLeft <= 0) {
            setIsFinished(true);
            setTimerRunning(false);
            return;
        }
        const id = setInterval(() => setTimeLeft((s) => s - 1), 1000);
        return () => clearInterval(id);
    }, [timerRunning, timeLeft]);

    const startRecording = useCallback(async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
            const preferredMime = MediaRecorder.isTypeSupported("audio/mp4") ? "audio/mp4" : "audio/webm";
            setRecMime(preferredMime);
            const recorder = new MediaRecorder(stream, { mimeType: preferredMime });
            const chunks = [];
            recorder.ondataavailable = (e) => e.data && chunks.push(e.data);
            recorder.start();
            recorder.chunks = chunks;
            setMediaRecorder(recorder);
            setIsRecording(true);
        } catch (err) {
            console.error("Recording start error:", err);
            toast.error("ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”.");
        }
    }, []);

    const stopRecording = useCallback(() => {
        if (!mediaRecorder) return;
        mediaRecorder.onstop = async () => {
            setLoadingText("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤...");
            setLoading(true);
            const type = recMime || "audio/webm";
            const audioBlob = new Blob(mediaRecorder.chunks, { type });
            setAudioURL(URL.createObjectURL(audioBlob));
            try {
                const formData = new FormData();
                formData.append("audio", audioBlob, `recording.${type.split("/")[1]}`);
                const res = await fetch(`${API_BASE}/transcribe`, { method: "POST", body: formData });
                if (!res.ok) throw new Error("Transcription failed");
                const data = await res.json();
                if (data.text) setMemo(data.text);
            } catch (e) {
                console.error("Transcription error:", e);
                toast.error("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
            } finally {
                setLoading(false);
            }
        };
        mediaRecorder.stop();
        setIsRecording(false);
        setIsFinished(true);
    }, [mediaRecorder, recMime, setLoading, setLoadingText]);

    const fetchBestAnswerFromGPT = useCallback(async () => {
        if (!question.trim()) return toast.error("ì§ˆë¬¸ì´ ë¨¼ì € í•„ìš”í•´ìš”!");
        setLoadingText("ëª¨ë²”ë‹µì•ˆì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...");
        setLoading(true);
        try {
            const targetBand = localStorage.getItem(LS.level) || "IM2â€“IH";
            const modelAnswerPrompt = `
You are an OPIC rater and coach. Write a model answer in English for the prompt at ${targetBand} level.
Constraints: 130â€“170 words, first-person, friendly spoken style, clear structure with examples.
Prompt: ${question}`.trim();
            const res = await fetch(`${API_BASE}/ask`, {
                method: "POST", headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ question: modelAnswerPrompt }),
            });
            const data = await res.json();
            const answer = (data?.answer || "").trim();
            if (answer) {
                setMemo((prev) => prev + `\n\n\nâ¡ï¸ AI ëª¨ë²”ë‹µì•ˆ:\n\n${answer}`);
            } else {
                toast.error("ëª¨ë²”ë‹µì•ˆ ìƒì„± ì‹¤íŒ¨");
            }
        } finally {
            setLoading(false);
        }
    }, [question, setLoading, setLoadingText]);

    const handleSave = useCallback(() => {
        if (!memo.trim()) return toast.error("ğŸ“ ë‹µë³€ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!");
        const saved = JSON.parse(localStorage.getItem(LS.history) || "[]");
        const separator = "â¡ï¸ AI ëª¨ë²”ë‹µì•ˆ:";
        const newEntry = {
            question,
            memo: memo.split(separator)[0].trim(),
            gptAnswer: memo.includes(separator) ? memo.split(separator)[1].trim() : "",
        };
        localStorage.setItem(LS.history, JSON.stringify([...saved, newEntry]));
        toast.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!");
    }, [memo, question]);

    const handleGoToReview = useCallback(() => {
        const history = JSON.parse(localStorage.getItem(LS.history) || "[]");
        if (history.length === 0) return toast.error("ì €ì¥ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.");
        setSavedHistory(history);
        setUi("review");
    }, [setSavedHistory, setUi]);

    return (
        <div className="App started">
            <h2>{question}</h2>
            <h3>ë‚¨ì€ ì‹œê°„: {timeLeft}ì´ˆ</h3>
            <div style={{ position: "relative", width: 360, height: 360, marginTop: 16 }}>
                <video ref={videoRef} src="/avatar.mp4" muted playsInline loop preload="auto" style={{ position: "absolute", inset: 0, width: "100%", height: "100%", borderRadius: 16, objectFit: "cover", background: "#000" }} />
                <audio ref={audioRef} />
                {needVideoGesture && (
                    <button className="btn primary" style={{ position: "absolute", inset: 0, margin: "auto", height: 56, width: 220, backdropFilter: "blur(2px)", }}
                        onClick={async () => {
                            const url = pendingAudioUrlRef.current;
                            if (url) {
                                await playAudioAndVideo(url);
                            }
                        }}>
                        â–¶ ì•„ë°”íƒ€ ì¬ìƒí•˜ê¸°
                    </button>
                )}
            </div>
            <button className="btn primary" onClick={() => { if (audioRef.current.src) playAudioAndVideo(audioRef.current.src); }} style={{ marginTop: 12 }}>
                â–¶ ë‹¤ì‹œ ë“£ê¸°
            </button>
            {!isRecording ? (
                <button onClick={startRecording} disabled={!timerRunning} style={{ marginTop: 16 }}>
                    <i className="fa-solid fa-microphone" aria-hidden="true"></i>{" "}
                    {timerRunning ? "ë‹µë³€ ë…¹ìŒ ì‹œì‘" : "ì§ˆë¬¸ ë“£ê³  ë‹µë³€í•˜ì„¸ìš”"}
                </button>
            ) : (
                <button onClick={stopRecording} style={{ marginTop: 16 }}>
                    <i className="fa-solid fa-circle-stop" aria-hidden="true"></i> ë…¹ìŒ ì •ì§€
                </button>
            )}
            {audioURL && <div style={{ marginTop: 12 }}><audio controls src={audioURL} /></div>}
            <button onClick={runOne} disabled={bankLoading} style={{ marginTop: 16 }}>
                <i className="fa-solid fa-shuffle" aria-hidden="true"></i>{" "}
                {bankLoading ? "ìƒˆ ì§ˆë¬¸ ë¡œë”©â€¦" : "ë‹¤ë¥¸ ì§ˆë¬¸ ë°›ê¸°"}
            </button>
            <div style={{ marginTop: 40, width: "100%", maxWidth: "600px" }}>
                <h3>ğŸ“ ë‚´ ë‹µë³€ ë©”ëª¨í•˜ê¸°</h3>
                <textarea value={memo} onChange={(e) => setMemo(e.target.value)} rows={5} placeholder="ì—¬ê¸°ì— ì˜ì–´ë¡œ ë§í•œ ë‚´ìš©ì„ ì ì–´ë³´ì„¸ìš”!" />
            </div>
            {isFinished && (
                <>
                    <button onClick={fetchBestAnswerFromGPT}><i className="fa-solid fa-wand-magic" aria-hidden="true"></i> ëª¨ë²”ë‹µì•ˆ ìš”ì²­í•˜ê¸°</button>
                    <button onClick={handleSave}><i className="fa-solid fa-floppy-disk" aria-hidden="true"></i> ì§ˆë¬¸ + ë©”ëª¨ ì €ì¥</button>
                    <button onClick={handleGoToReview}><i className="fa-solid fa-folder-open" aria-hidden="true"></i> ì €ì¥ëœ ì§ˆë¬¸/ë‹µë³€ ë³´ê¸°</button>
                </>
            )}
            <div className="practice-actions">
                <button type="button" className="btn-reset" onClick={() => setUi("survey")} title="ì„¤ë¬¸ ë‹¤ì‹œí•˜ê¸°">
                    <i className="fa-solid fa-arrow-left icon-nudge" aria-hidden="true"></i> ì„¤ë¬¸ ë‹¤ì‹œí•˜ê¸°
                </button>
            </div>
        </div>
    );
}
export default Practice;